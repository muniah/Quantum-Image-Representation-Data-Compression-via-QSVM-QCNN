{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.7.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit_machine_learning\n",
    "qiskit_machine_learning.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import tensorflow as tf # type: ignore\n",
    "from tensorflow.keras import datasets, layers, models   # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "import time\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import warnings # type: ignore\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.primitives import Sampler\n",
    "\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "from qiskit_algorithms.state_fidelities import ComputeUncompute\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    " \n",
    "import os\n",
    "import certifi # type: ignore\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected classes: [8 3]\n",
      "(15, 4, 4, 3) (5, 4, 4, 3) (15, 2) (5, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Randomly select 2 classes\n",
    "num_classes = 10\n",
    "selected_classes = np.random.choice(range(num_classes), 2, replace=False)\n",
    "print(f\"Selected classes: {selected_classes}\")\n",
    "\n",
    "# Filter the train and test datasets to include only the selected classes\n",
    "train_mask = np.isin(y_train, selected_classes)\n",
    "test_mask = np.isin(y_test, selected_classes)\n",
    "\n",
    "x_train = x_train[train_mask.squeeze()]\n",
    "y_train = y_train[train_mask.squeeze()]\n",
    "x_test = x_test[test_mask.squeeze()]\n",
    "y_test = y_test[test_mask.squeeze()]\n",
    "\n",
    "idx_train = 15\n",
    "idx_test = 5\n",
    "x_train = x_train[:idx_train]\n",
    "x_test = x_test[:idx_test]\n",
    "y_train = y_train[:idx_train]\n",
    "y_test = y_test[:idx_test]\n",
    "\n",
    "# Resize images to 8x8\n",
    "# Resize images to 4x4\n",
    "\n",
    "im_size = 4\n",
    "x_train = tf.image.resize(x_train, (im_size, im_size)).numpy()\n",
    "x_test = tf.image.resize(x_test, (im_size, im_size)).numpy()\n",
    "\n",
    "# Normalize the pixel values to [0, 1]\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# One-hot encode the labels for the selected classes\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)[:, selected_classes]\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)[:, selected_classes]\n",
    "\n",
    "# Display the shapes of the processed datasets\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 16), (5, 16))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_gray = tf.image.rgb_to_grayscale(x_train).numpy()\n",
    "x_test_gray = tf.image.rgb_to_grayscale(x_test).numpy()\n",
    "\n",
    "# Reshape the data to 1D vectors\n",
    "x_train_rs = x_train_gray.reshape(x_train_gray.shape[0], -1)\n",
    "x_test_rs = x_test_gray.reshape(x_test_gray.shape[0], -1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Standardize the data to have a mean of 0 and variance of 1\n",
    "scaler = StandardScaler()\n",
    "x_train_s = scaler.fit_transform(x_train_rs)\n",
    "x_test_s = scaler.transform(x_test_rs)\n",
    "\n",
    "x_train_s.shape , x_test_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (15, 16)\n",
      "Reduced shape: (15, 8)\n",
      "Explained variance by 8 components: 95.08%\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA for feature reduction\n",
    "from sklearn.decomposition import PCA\n",
    "n_components = 8\n",
    "pca = PCA(n_components=n_components)\n",
    "x_train_pca = pca.fit_transform(x_train_s)\n",
    "x_test_pca = pca.transform(x_test_s)\n",
    "\n",
    "# Output the shape of the reduced data\n",
    "print(f\"Original shape: {x_train_s.shape}\")\n",
    "print(f\"Reduced shape: {x_train_pca.shape}\")\n",
    "\n",
    "# Optional: Show explained variance to understand the amount of information retained\n",
    "explained_variance = np.sum(pca.explained_variance_ratio_)\n",
    "print(f\"Explained variance by {n_components} components: {explained_variance * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum SVM with feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 3.1 µs\n",
      "Training set accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "%time\n",
    "t0 = time.time()\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension = n_components, entanglement= \"full\")\n",
    "\n",
    "fidelity = ComputeUncompute(sampler=Sampler())\n",
    "new_kernel = FidelityQuantumKernel(feature_map=feature_map, fidelity=fidelity)\n",
    "\n",
    "qsvc = QSVC(quantum_kernel=new_kernel)\n",
    "\n",
    "qsvc.fit(x_train_pca, y_train.argmax(axis=1))\n",
    "t1 = time.time()\n",
    "print(f'Training set accuracy {qsvc.score(x_train_pca, y_train.argmax(axis=1))}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set accuracy: {qsvc.score(x_test_pca, y_test.argmax(axis=1))}\")\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for training and testing:(0.9252398014068604, 1.7010149955749512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Time taken for training and testing:{t1-t0, t2-t1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSVM Insights: \n",
    "\n",
    "1. Training set accuracy 100%\n",
    "2. Testing set accuracy with SVM: 50.00%\n",
    "3. Train dataset size = 500, test size = 10\n",
    "4. Randomly chosen 2 classes out of 10\n",
    "5. Eache image is 8x8 pizel in size\n",
    "6. Train time: 22 s, Test time: 25 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QSVM - toy dataset Insights: \n",
    "\n",
    "1. Training set accuracy 100%\n",
    "2. Testing set accuracy with SVM: 40.00%\n",
    "3. Train dataset size = 15, test size = 5\n",
    "4. Randomly chosen 2 classes out of 10\n",
    "5. Eache image is 4x4 pizel in size\n",
    "6. Train time: 1.03 s, Test time: 5.36 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
